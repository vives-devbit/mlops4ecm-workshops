
# Building ML Infrastructure and Deploying Production-Ready Models

This workshop is part of the "Building ML Infrastructure" course:

- ğŸ“š Read the full [written guide](https://mlops4ecm.be/handleidingen/ml-infrastructure/) with detailed explanations
- ğŸ§ Listen to the [podcast episodes](https://mlops4ecm.be/handleidingen/ml-infrastructure/) for an audio companion
- ğŸ“„ Download the [slide deck (PDF)](https://mlops4ecm.be/handleidingen/Building%20ML%20Infrastructure.pdf) for a visual summary

Whether you prefer reading, listening, or experimenting â€” we've got you covered.

## ğŸ§­ Lab Overview

<img src="../media/ml-infrastructure-server-rack-data-center.jpg" style="width: 300px" align="right">

Welcome to the **ML Infrastructure Workshop** â€” a hands-on series of labs designed to take you from notebook experimentation to fully automated, production-grade machine learning systems.

Each lab builds on the previous one, gradually introducing real-world tools and practices used in modern MLOps environments.

### Lab 01 â€“ [Running the Notebook](01-running-the-notebook/)

Set up a virtual machine, configure your Python environment, and run a notebook that trains a MobileNet classifier on grocery item images.

### Lab 02 â€“ [Refactor the Notebook](02-refactor-the-notebook/)

Turn your Jupyter notebook into a clean, testable Python project. Refactor the code into reusable modules, build a script for automated training, and add your first unit tests.

### Lab 03 â€“ [Notebook Visualization](03-notebook-visualization/)

Use Jupyter notebooks to explore model behavior, identify weak spots, and inspect dataset structure. No training is performed here â€” just analysis and visualization.

### Lab 04 â€“ [Backend with FastAPI](04-backend-with-fastapi/)

Serve your trained model through a REST API built with FastAPI. Create an endpoint that accepts image uploads and returns predictions.

### Lab 05 â€“ [Connect the Frontend](05-connect-the-frontend/)

Integrate a Dash-based frontend with your API. Let users upload images and see model predictions in a simple web interface.

### Lab 06 â€“ [Docker Containers](06-docker-containers/)

<img src="../media/containers-shipping-analogy.jpg" style="width: 300px" align="right">

Package both the backend and frontend into Docker containers to ensure reproducibility and portability across systems.

### Lab 07 â€“ [Compose Deployment](07-compose-deployment/)

Use Docker Compose to launch your entire application stack (API + frontend) with a single command.

### Lab 08 â€“ [Deploy Model from S3](08-deploy-model-from-s3/)

Move your training dataset to S3 and modify your code to load it from object storage instead of local disk â€” just like in cloud pipelines.

### Lab 09 â€“ [Pull Request Checks](09-pull-request-checks/)

Add continuous integration (CI) checks to your project using GitHub Actions. Automatically test your code and check formatting every time someone opens a pull request.

## ğŸš€ Goal of the Workshop

By the end of these labs, you'll have built a real, end-to-end machine learning system that can:

- Ingest and process data
- Train and evaluate models
- Serve predictions via API and UI
- Automate deployments and retraining

You'll also gain hands-on experience with tools like **FastAPI**, **Docker Compose**, **MinIO S3**, and **GitHub Actions** â€” all key components of a modern MLOps toolkit.

## ğŸ› ï¸ Prerequisites

- Basic Python and Git knowledge
- Familiarity with machine learning (e.g. training a model in PyTorch)
- Willingness to use the terminal and VS Code
- Some exposure to Linux and SSH is helpful
