{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8aa759ae",
   "metadata": {},
   "source": [
    "### ðŸ§  Interactive Prediction Explorer with Gradio\n",
    "\n",
    "In this notebook, youâ€™ll create a simple **interactive tool** that helps you visually explore how well your trained image classifier performs.\n",
    "\n",
    "The idea is straightforward but powerful:\n",
    "\n",
    "- **Pick a class label** (e.g. apple, kiwi, tomato) from a dropdown menu,\n",
    "- The tool will randomly select **5 validation images** from that class,\n",
    "- It will run them through your **trained MobileNet model**,\n",
    "- And display the images side by side, along with the modelâ€™s **predicted class** for each.\n",
    "\n",
    "This interface is built using [Gradio](https://gradio.app/) â€” a Python library that lets you build UI components quickly and easily, directly from your code. Itâ€™s great for **debugging**, **demonstrations**, or just getting a better feel for how your model behaves.\n",
    "\n",
    "âœ… Make sure Gradio is installed: `pip install gradio`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d714759a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "from data_utils import get_classes, GroceryDataset, transform, VAL_CSV\n",
    "from model_utils import load_model, DEVICE\n",
    "import torch\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load class labels and model\n",
    "classes = get_classes()\n",
    "model = load_model(num_classes=len(classes))\n",
    "model.eval()\n",
    "\n",
    "# Load validation dataset\n",
    "dataset = GroceryDataset(csv_file=VAL_CSV, transform=transform)\n",
    "\n",
    "# âœ… Group images by class name\n",
    "images_by_class = {}  # e.g. \"fruits\" => [img1, img2, ...]\n",
    "\n",
    "for image, label in dataset:\n",
    "    class_name = classes[label]\n",
    "    if class_name not in images_by_class:\n",
    "        images_by_class[class_name] = []\n",
    "    images_by_class[class_name].append(image)\n",
    "\n",
    "# âœ… This function is complete â€” no changes needed\n",
    "def get_random_images(class_name, n=5):\n",
    "    \"\"\"Return N random images from the selected class.\"\"\"\n",
    "    matching = images_by_class[class_name]\n",
    "    return random.sample(matching, min(n, len(matching)))\n",
    "\n",
    "\n",
    "def predict(class_name):\n",
    "    images = get_random_images(class_name, n=5)\n",
    "    outputs = model(torch.stack(images).to(DEVICE))\n",
    "    _, preds = torch.max(outputs, 1)\n",
    "    preds = preds.cpu().numpy()\n",
    "\n",
    "    fig, axs = plt.subplots(1, len(images), figsize=(15, 3))\n",
    "    for i, ax in enumerate(axs):\n",
    "        img = images[i].permute(1, 2, 0).numpy()\n",
    "        img = img * [0.229, 0.224, 0.225] + [0.485, 0.456, 0.406]  # unnormalize\n",
    "        img = img.clip(0, 1)\n",
    "        ax.imshow(img)\n",
    "        ax.axis(\"off\")\n",
    "        ax.set_title(f\"Pred: {classes[preds[i]]}\")\n",
    "    return fig\n",
    "\n",
    "\n",
    "# âœ… Launch the Gradio UI\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"### ðŸ›’ Grocery Classifier Explorer\")\n",
    "    class_dropdown = gr.Dropdown(choices=list(classes.values()), label=\"Select a class\")\n",
    "    output_plot = gr.Plot()\n",
    "    run_btn = gr.Button(\"Show predictions\")\n",
    "    run_btn.click(fn=predict, inputs=class_dropdown, outputs=output_plot)\n",
    "\n",
    "demo.launch(server_name=\"10.26.26.x\")  # TODO set your IP address"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
