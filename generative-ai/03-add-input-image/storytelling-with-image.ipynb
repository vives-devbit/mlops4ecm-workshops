{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18c9f827",
   "metadata": {},
   "source": [
    "# üìñ Lab 3 (Part 2) ‚Äì Add an Image to Your Storytelling Assistant\n",
    "\n",
    "In this follow-up to the previous lab, you'll combine two powerful capabilities:\n",
    "\n",
    "‚úÖ Large language models for story generation  \n",
    "‚úÖ Vision input to guide the story using an image\n",
    "\n",
    "You're still working with a storytelling assistant, but now it will receive both a **system prompt** *and* a reference image (like `scene.jpg`) as context. The model will be instructed to use the image as the setting or inspiration for the story.\n",
    "\n",
    "üß† Your task is to:\n",
    "- Write a **user prompt** that guides the direction of the story\n",
    "- Let the **system prompt** and image handle the mood and setting\n",
    "\n",
    "For example:\n",
    "> \"One of the objects in this scene becomes alive.\"\n",
    "\n",
    "The model will take your prompt and combine it with the uploaded image to generate a vivid story.\n",
    "\n",
    "üéØ Goal: See how much the image influences the storytelling output when passed through the system prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8aafe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "from PIL import Image\n",
    "import ollama\n",
    "\n",
    "# Set path to the scene image\n",
    "path_to_image = \"scene.jpg\"  # Make sure this image is in the same folder\n",
    "\n",
    "# Show the image below\n",
    "Image.open(path_to_image).show()\n",
    "\n",
    "# System prompt that includes the image as a visual guide\n",
    "system_prompt = \"\"\"\n",
    "You are a storyteller. Always reply with stories full of imagination.\n",
    "Use the image provided as the setting for your story.\n",
    "\"\"\"\n",
    "\n",
    "# TODO: Enter your own creative story idea here!\n",
    "user_prompt = \"\"  # ‚Üê Fill this in\n",
    "\n",
    "assert user_prompt != \"\"\n",
    "\n",
    "# Generate a response using Ollama, passing the image to the system prompt\n",
    "response = ollama.chat(\n",
    "    model='gemma3:4b-it-qat',\n",
    "    messages=[\n",
    "        {'role': 'system', 'content': system_prompt, 'images': [path_to_image]},\n",
    "        {'role': 'user', 'content': user_prompt}\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Display the story\n",
    "display(Markdown(response['message']['content']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
