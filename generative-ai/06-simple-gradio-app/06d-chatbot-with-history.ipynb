{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8bec340d",
   "metadata": {},
   "source": [
    "# ðŸ’¬ Stateful Chatbot with Gradio and Ollama\n",
    "\n",
    "In this notebook, you'll explore how to build a **chatbot** that remembers your previous messages.\n",
    "\n",
    "You'll learn how to:\n",
    "- Use `gr.Chatbot` to display a back-and-forth conversation\n",
    "- Maintain a **chat history** using `gr.State`\n",
    "- Pass the full conversation history to a language model\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ§  How State Works\n",
    "\n",
    "Each time you send a message, the chatbot:\n",
    "1. Collects the full chat history (all previous user and model messages)\n",
    "2. Sends it to the model, along with your new message\n",
    "3. Adds the model's response to the history\n",
    "4. Displays the updated conversation\n",
    "\n",
    "You donâ€™t need to fix anything in this example â€” just run the code and try talking to your friendly wizard! ðŸ§™"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b3d5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import ollama\n",
    "\n",
    "MODEL = \"gemma3:4b-it-qat\"\n",
    "\n",
    "# System prompt to set behavior\n",
    "SYSTEM_PROMPT = \"You are a helpful and kind wizard.\"\n",
    "\n",
    "# Core function that takes the current message and chat history\n",
    "def chat(user_input, history):\n",
    "    if not user_input.strip():\n",
    "        return \"\", history\n",
    "\n",
    "    # Rebuild full message list including system prompt\n",
    "    messages = [{\"role\": \"system\", \"content\": SYSTEM_PROMPT}]\n",
    "    for human, bot in history:\n",
    "        messages.append({\"role\": \"user\", \"content\": human})\n",
    "        messages.append({\"role\": \"assistant\", \"content\": bot})\n",
    "\n",
    "    # Add the new user input\n",
    "    messages.append({\"role\": \"user\", \"content\": user_input})\n",
    "\n",
    "    # Call the model\n",
    "    response = ollama.chat(\n",
    "        model=MODEL,\n",
    "        messages=messages\n",
    "    )\n",
    "\n",
    "    assistant_reply = response[\"message\"][\"content\"]\n",
    "\n",
    "    # Update chat history\n",
    "    history.append((user_input, assistant_reply))\n",
    "\n",
    "    return \"\", history, history\n",
    "\n",
    "# Gradio UI\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"## ðŸ§™ Stateful LLM Chatbot\\nTalk to a wizard who remembers your past messages.\")\n",
    "    chatbot = gr.Chatbot()\n",
    "    msg = gr.Textbox(label=\"Your message\", placeholder=\"Type something...\")\n",
    "    state = gr.State([])  # Stores the chat history\n",
    "\n",
    "    msg.submit(chat, [msg, state], [msg, chatbot, state])\n",
    "\n",
    "demo.launch(server_name=\"0.0.0.0\", server_port=8080)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
