{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5951cafc",
   "metadata": {},
   "source": [
    "# üß© Lab 4 ‚Äì Structured Story Generation with Chaining\n",
    "\n",
    "In this notebook, you'll break your story into multiple parts and generate it step by step using a large language model.\n",
    "\n",
    "Instead of generating the full story in one go, you'll first ask the model to create a table of contents, and then generate each chapter separately. This teaches you how to **call the model multiple times** and **use its output as input** for the next step.\n",
    "\n",
    "You'll need to:\n",
    "- Write your own creative story idea\n",
    "- Parse the model's output into clean chapter summaries\n",
    "- Accumulate the story as you go\n",
    "\n",
    "By the end, you'll have a **multi-part story** with coherent structure and flow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d925085b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "import ollama\n",
    "\n",
    "# üîß Configuration\n",
    "MODEL_NAME = \"gemma3:4b-it-qat\"  # You can try larger models if GPU allows\n",
    "NUM_PARTS = 5  # How many chapters should the story have\n",
    "\n",
    "# TODO: Write your own story idea below! Be creative.\n",
    "story_idea = \"\"\n",
    "\n",
    "assert story_idea != \"\"\n",
    "\n",
    "\n",
    "# STEP 1: Generate abstracts / table of content\n",
    "\n",
    "system_prompt_toc = f\"\"\"\n",
    "You are a storyteller. We're going to generate a multi-part story.\n",
    "Your task is to plan the structure, by generating story abstracts.\n",
    "\n",
    "Given the user prompt as idea, generate {NUM_PARTS} one-line abstracts.\n",
    "Each abstract should represent the content of one part of the story.\n",
    "Do not write the full story yet. Just output the abstracts, one per line.\n",
    "Only output the {NUM_PARTS} one-line abstracts. Nothing else.\n",
    "No extra explanations. No empty lines. No chit chat.\n",
    "\"\"\"\n",
    "\n",
    "# Generate the list of abstracts\n",
    "response_toc = ollama.chat(\n",
    "    model=MODEL_NAME,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_prompt_toc},\n",
    "        {\"role\": \"user\", \"content\": story_idea}\n",
    "    ]\n",
    ")\n",
    "\n",
    "abstracts_raw = response_toc['message']['content'].strip()\n",
    "\n",
    "# TODO: Turn the raw response into a list of clean one-line abstracts\n",
    "# Make sure to remove empty lines and extra whitespace.\n",
    "# Hint: Use .split(\"\\n\") to break lines, then .strip() to remove whitespace.\n",
    "abstracts = []  # ‚Üê You'll need to extract clean lines from `abstracts_raw`\n",
    "\n",
    "assert len(abstracts) != 0\n",
    "\n",
    "abstracts_full = \"\\n\".join(abstracts)\n",
    "\n",
    "print(\"=== Abstracts ===\")\n",
    "print(abstracts_full)\n",
    "\n",
    "# STEP 2: Generate story parts\n",
    "\n",
    "full_story_so_far = \"\"\n",
    "\n",
    "for i, abstract in enumerate(abstracts):\n",
    "    system_prompt_chapter = f\"\"\"\n",
    "You are a storyteller. We're building a multi-part story.\n",
    "Please write the next part of the story.\n",
    "Use previous parts as context to ensure continuity.\n",
    "Make sure the text flows naturally from earlier events.\n",
    "\"\"\"\n",
    "\n",
    "    user_prompt_chapter = f\"\"\"\n",
    "All abstracts for the full story (one per line):\n",
    "{abstracts_full}\n",
    "\n",
    "Here is the story so far:\n",
    "{full_story_so_far}\n",
    "\n",
    "Now continue with part {i+1}: {abstract}\n",
    "Each part should be no more than 2 paragraphs!\n",
    "\"\"\"\n",
    "\n",
    "    response_chapter = ollama.chat(\n",
    "        model=MODEL_NAME,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt_chapter},\n",
    "            {\"role\": \"user\", \"content\": user_prompt_chapter}\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    chapter_text = response_chapter[\"message\"][\"content\"].strip()\n",
    "\n",
    "    # TODO: Accumulate the story so far by appending this chapter\n",
    "    # (Hint: use += to add the current chapter text)\n",
    "    # full_story_so_far = ...\n",
    "\n",
    "    assert full_story_so_far != \"\"\n",
    "\n",
    "    # STEP 3: Display the Final Story\n",
    "    display(Markdown(f\"### Part {i+1}: {abstract}\\n\\n\"))\n",
    "    display(Markdown(chapter_text))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
