{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30820796",
   "metadata": {},
   "source": [
    "# üéº Music Generation with MusicGen\n",
    "\n",
    "In this notebook, you'll generate short music clips using **text prompts** and Meta's MusicGen models. You‚Äôll be able to describe a musical style or mood ‚Äî like `\"A calm piano melody with rain in the background\"` ‚Äî and the model will generate a unique audio sample for you.\n",
    "\n",
    "You can choose between two model sizes:\n",
    "- **Small (300M)** ‚Äì Fast, but lower quality and less expressive.\n",
    "- **Medium (1.5B)** ‚Äì Better sound quality and more musical nuance, but **much slower**, especially for longer clips.\n",
    "\n",
    "‚ö†Ô∏è **Tip:** If you select the **medium model** and a clip length longer than 15 seconds, generation may take **up to several minutes**. Start small if you're just experimenting!\n",
    "\n",
    "Once your clip is ready, you can listen to it directly in the notebook üéß"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1976ff5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "from transformers import pipeline\n",
    "import scipy\n",
    "\n",
    "# Model selection options\n",
    "MODEL_OPTIONS = {\n",
    "    \"Small (300M)\": \"facebook/musicgen-small\",\n",
    "    \"Medium (1.5B)\": \"facebook/musicgen-medium\"\n",
    "}\n",
    "\n",
    "def generate_music(prompt, model_name, length_seconds):\n",
    "    model_id = MODEL_OPTIONS[model_name]\n",
    "    synthesiser = pipeline(\"text-to-audio\", model=model_id)\n",
    "    \n",
    "    # Token estimation: ~50 tokens per second\n",
    "    max_tokens = int(length_seconds * 50)\n",
    "    params = {\"do_sample\": True, \"max_new_tokens\": max_tokens}\n",
    "    \n",
    "    out = synthesiser(prompt, forward_params=params)\n",
    "    audio = out[\"audio\"][0] if isinstance(out[\"audio\"], list) else out[\"audio\"]\n",
    "    sr = out[\"sampling_rate\"]\n",
    "    \n",
    "    scipy.io.wavfile.write(\"music.wav\", rate=sr, data=audio)\n",
    "    return sr, audio\n",
    "\n",
    "gr.Interface(\n",
    "    fn=generate_music,\n",
    "    inputs=[\n",
    "        gr.Textbox(lines=2, label=\"Prompt\", placeholder=\"e.g. Energetic synthwave track with retro vibes\"),\n",
    "        gr.Dropdown(list(MODEL_OPTIONS.keys()), value=\"Small (300M)\", label=\"Model\"),\n",
    "        gr.Slider(minimum=5, maximum=30, step=1, value=10, label=\"Clip Length (seconds)\")\n",
    "    ],\n",
    "    outputs=gr.Audio(type=\"numpy\", label=\"Generated Music\"),\n",
    "    title=\"üé∂ MusicGen Text‚Äëto‚ÄëMusic\",\n",
    "    description=\"Generate music from text using Facebook's MusicGen. Choose your model and clip length.\"\n",
    ").launch(server_name=\"0.0.0.0\", server_port=8080, share=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
